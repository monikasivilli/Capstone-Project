{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Table of Contents: </b>\n",
    "<b> Target Variable: Death Rate Categories </b>\n",
    "<br> [1.0 Basic Model Decision Tree Classifier - Death Rate](#123)\n",
    "        <br> [1.1 Oversampling (SMOTE)](#1234)\n",
    "        <br> [1.2 Cross Validation (Oversampling) - BEST RESULT](#12345)\n",
    "        <br> [1.3 Cross Validation (Undersampling)](#123456)\n",
    "<br> [2.0 Basic Model Decision Tree Classifier - Case Rate](#1234567)\n",
    "        <br> [2.1 Oversampling (SMOTE)](#12345678)\n",
    "        <br> [2.2 Cross Validation (Oversampling)](#123456789)\n",
    "        <br> [2.3 Cross Validation (Undersampling)](#1234567891)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree, metrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss \n",
    "\n",
    "# Cross Validation packages\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# import module for gridsearch (to find optimal hyper-parameters)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import module (to test execution time of a codeblock to run)\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "# packages for Receiver Operating Characteristic (ROC) with cross validation\n",
    "# source: https://scikit-learn.org/0.18/auto_examples/model_selection/plot_roc_crossval.html\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Model - Target Variable 'Case Rate Categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Total Citizen Income</th>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <th>Total Citizen Educated in US</th>\n",
       "      <th>Total Households</th>\n",
       "      <th>White Race</th>\n",
       "      <th>Total Families</th>\n",
       "      <th>Citizen College Degree</th>\n",
       "      <th>Citizen Some College  Education</th>\n",
       "      <th>Citizen Income over 75000</th>\n",
       "      <th>Citizen High School  Graduate</th>\n",
       "      <th>Citizen No Income</th>\n",
       "      <th>Pacific Islander Race</th>\n",
       "      <th>Citizen Graduate or Professional Degree</th>\n",
       "      <th>Citizen Income 1-9999</th>\n",
       "      <th>Citizen Less than High School  Education</th>\n",
       "      <th>Citizen Income 15000-24999</th>\n",
       "      <th>Citizen Income 15000-24999.1</th>\n",
       "      <th>Citizen Income 35000-49999</th>\n",
       "      <th>Case Rate Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54571</td>\n",
       "      <td>44109</td>\n",
       "      <td>53261</td>\n",
       "      <td>36757</td>\n",
       "      <td>20221</td>\n",
       "      <td>9643</td>\n",
       "      <td>14613</td>\n",
       "      <td>5316</td>\n",
       "      <td>10697</td>\n",
       "      <td>5298</td>\n",
       "      <td>12363</td>\n",
       "      <td>6377</td>\n",
       "      <td>466</td>\n",
       "      <td>3860</td>\n",
       "      <td>6955</td>\n",
       "      <td>4521</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "      <td>5727</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>182265</td>\n",
       "      <td>166364</td>\n",
       "      <td>174273</td>\n",
       "      <td>143022</td>\n",
       "      <td>73180</td>\n",
       "      <td>17105</td>\n",
       "      <td>41898</td>\n",
       "      <td>29237</td>\n",
       "      <td>45286</td>\n",
       "      <td>17954</td>\n",
       "      <td>39771</td>\n",
       "      <td>20201</td>\n",
       "      <td>3631</td>\n",
       "      <td>14731</td>\n",
       "      <td>25080</td>\n",
       "      <td>13997</td>\n",
       "      <td>26852</td>\n",
       "      <td>26852</td>\n",
       "      <td>21502</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27457</td>\n",
       "      <td>21627</td>\n",
       "      <td>26070</td>\n",
       "      <td>18434</td>\n",
       "      <td>9820</td>\n",
       "      <td>12875</td>\n",
       "      <td>6015</td>\n",
       "      <td>1403</td>\n",
       "      <td>4707</td>\n",
       "      <td>1019</td>\n",
       "      <td>6549</td>\n",
       "      <td>3968</td>\n",
       "      <td>894</td>\n",
       "      <td>815</td>\n",
       "      <td>5090</td>\n",
       "      <td>4960</td>\n",
       "      <td>3419</td>\n",
       "      <td>3419</td>\n",
       "      <td>1820</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22915</td>\n",
       "      <td>18743</td>\n",
       "      <td>22509</td>\n",
       "      <td>15859</td>\n",
       "      <td>7953</td>\n",
       "      <td>5047</td>\n",
       "      <td>5201</td>\n",
       "      <td>1289</td>\n",
       "      <td>3971</td>\n",
       "      <td>953</td>\n",
       "      <td>6958</td>\n",
       "      <td>4170</td>\n",
       "      <td>185</td>\n",
       "      <td>808</td>\n",
       "      <td>3268</td>\n",
       "      <td>2833</td>\n",
       "      <td>2926</td>\n",
       "      <td>2926</td>\n",
       "      <td>1860</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57322</td>\n",
       "      <td>46501</td>\n",
       "      <td>52696</td>\n",
       "      <td>39475</td>\n",
       "      <td>21578</td>\n",
       "      <td>761</td>\n",
       "      <td>14106</td>\n",
       "      <td>3416</td>\n",
       "      <td>13583</td>\n",
       "      <td>2690</td>\n",
       "      <td>12740</td>\n",
       "      <td>10165</td>\n",
       "      <td>2347</td>\n",
       "      <td>1756</td>\n",
       "      <td>6561</td>\n",
       "      <td>7980</td>\n",
       "      <td>6956</td>\n",
       "      <td>6956</td>\n",
       "      <td>5639</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Population  Total Citizen Income  Hispanic or Latino  \\\n",
       "0             54571                 44109               53261   \n",
       "1            182265                166364              174273   \n",
       "2             27457                 21627               26070   \n",
       "3             22915                 18743               22509   \n",
       "4             57322                 46501               52696   \n",
       "\n",
       "   Total Citizen Educated in US  Total Households  White Race  Total Families  \\\n",
       "0                         36757             20221        9643           14613   \n",
       "1                        143022             73180       17105           41898   \n",
       "2                         18434              9820       12875            6015   \n",
       "3                         15859              7953        5047            5201   \n",
       "4                         39475             21578         761           14106   \n",
       "\n",
       "   Citizen College Degree  Citizen Some College  Education  \\\n",
       "0                    5316                            10697   \n",
       "1                   29237                            45286   \n",
       "2                    1403                             4707   \n",
       "3                    1289                             3971   \n",
       "4                    3416                            13583   \n",
       "\n",
       "   Citizen Income over 75000  Citizen High School  Graduate  \\\n",
       "0                       5298                          12363   \n",
       "1                      17954                          39771   \n",
       "2                       1019                           6549   \n",
       "3                        953                           6958   \n",
       "4                       2690                          12740   \n",
       "\n",
       "   Citizen No Income  Pacific Islander Race  \\\n",
       "0               6377                    466   \n",
       "1              20201                   3631   \n",
       "2               3968                    894   \n",
       "3               4170                    185   \n",
       "4              10165                   2347   \n",
       "\n",
       "   Citizen Graduate or Professional Degree  Citizen Income 1-9999  \\\n",
       "0                                     3860                   6955   \n",
       "1                                    14731                  25080   \n",
       "2                                      815                   5090   \n",
       "3                                      808                   3268   \n",
       "4                                     1756                   6561   \n",
       "\n",
       "   Citizen Less than High School  Education  Citizen Income 15000-24999  \\\n",
       "0                                      4521                        6000   \n",
       "1                                     13997                       26852   \n",
       "2                                      4960                        3419   \n",
       "3                                      2833                        2926   \n",
       "4                                      7980                        6956   \n",
       "\n",
       "   Citizen Income 15000-24999.1  Citizen Income 35000-49999  \\\n",
       "0                          6000                        5727   \n",
       "1                         26852                       21502   \n",
       "2                          3419                        1820   \n",
       "3                          2926                        1860   \n",
       "4                          6956                        5639   \n",
       "\n",
       "   Case Rate Categories  \n",
       "0                     2  \n",
       "1                     2  \n",
       "2                     3  \n",
       "3                     2  \n",
       "4                     2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"final_case_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total Population                            int64\n",
       "Total Citizen Income                        int64\n",
       "Hispanic or Latino                          int64\n",
       "Total Citizen Educated in US                int64\n",
       "Total Households                            int64\n",
       "White Race                                  int64\n",
       "Total Families                              int64\n",
       "Citizen College Degree                      int64\n",
       "Citizen Some College  Education             int64\n",
       "Citizen Income over 75000                   int64\n",
       "Citizen High School  Graduate               int64\n",
       "Citizen No Income                           int64\n",
       "Pacific Islander Race                       int64\n",
       "Citizen Graduate or Professional Degree     int64\n",
       "Citizen Income 1-9999                       int64\n",
       "Citizen Less than High School  Education    int64\n",
       "Citizen Income 15000-24999                  int64\n",
       "Citizen Income 15000-24999.1                int64\n",
       "Citizen Income 35000-49999                  int64\n",
       "Case Rate Categories                        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the spaces of the cells from the csv file\n",
    "df.columns = df.columns.to_series().apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to change int64 to cat type for target vars\n",
    "df['Case Rate Categories'] = df['Case Rate Categories'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes\n",
    "#check to see if types changed to cat -- YES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"123\"> <h2> 1.0 Basic Model Decision Tree Classifier </h2> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Build the Model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variable is 'Case Rate Categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dependent and independent variables\n",
    "\n",
    "feature_cols = ['Total Population','Total Citizen Income','Hispanic or Latino','Total Citizen Educated in US',\n",
    "                                    'Total Households','White Race','Total Families','Citizen College Degree','Citizen Some College  Education',\n",
    "                                    'Citizen Income over 75000','Citizen High School  Graduate',\n",
    "                                    'Citizen No Income','Pacific Islander Race','Citizen Graduate or Professional Degree',\n",
    "                                    'Citizen Income 1-9999','Citizen Less than High School  Education',\n",
    "                                     'Citizen Income 15000-24999','Citizen Income 15000-24999','Citizen Income 35000-49999',\n",
    "                                    'Case Rate Categories']\n",
    "\n",
    "X = df.iloc[:, :-1] # Features is all columns in the dataframe except the last column\n",
    "Y = df.iloc[:, -1] # Target is the last column in the dataframe: 'Case Rate Categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5021231422505308\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.35      0.35        40\n",
      "           1       0.62      0.65      0.63       431\n",
      "           2       0.49      0.45      0.47       352\n",
      "           3       0.18      0.23      0.20        75\n",
      "           4       0.11      0.09      0.10        23\n",
      "           5       0.06      0.05      0.05        21\n",
      "\n",
      "    accuracy                           0.50       942\n",
      "   macro avg       0.30      0.30      0.30       942\n",
      "weighted avg       0.50      0.50      0.50       942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14  23   3   0   0   0]\n",
      " [ 19 279 110  16   4   3]\n",
      " [  7 121 160  50   8   6]\n",
      " [  0  15  36  17   3   4]\n",
      " [  1   4   8   5   2   3]\n",
      " [  0   6   9   4   1   1]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Graph of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-01a20347c81f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m export_graphviz(clf, out_file=dot_data,  \n\u001b[1;32m     11\u001b[0m                 \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 special_characters=True, feature_names = feature_cols,class_names=['0','1'])\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'covid_census.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    743\u001b[0m     \"\"\"\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m     \u001b[0mown_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0mreturn_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# source: https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import pydotplus\n",
    "\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names = feature_cols,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('covid_census.png')\n",
    "Image(graph.create_png())\n",
    "\n",
    "# sizing of the decision tree \n",
    "check_is_fitted(decision_tree, 'tree_')\n",
    "best_clf = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-1414174bff3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m export_graphviz(clf, out_file=dot_data,  \n\u001b[1;32m      8\u001b[0m                 \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COVID_case.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    743\u001b[0m     \"\"\"\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m     \u001b[0mown_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0mreturn_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('COVID_case.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# check for the sklearn version, it has to be 0.21\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-d2b03071ae20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#max_depth is maximum number of levels in the tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m a = plot_tree(clf, \n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3) #max_depth is maximum number of levels in the tree\n",
    "clf.fit(df.data, df.target)\n",
    "\n",
    "plt.figure(figsize=(25,10))\n",
    "a = plot_tree(clf, \n",
    "              feature_names=df.feature_names, \n",
    "              class_names=df.target_names, \n",
    "              filled=True, \n",
    "              rounded=True, \n",
    "              fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"1234\"> <h2> 1.1 Oversampling (SMOTE) </h2> </a>\n",
    "We oversample the <b> training </b> dataset, because the classes within our target variable 'Revenue' are imbalanced:\n",
    "* class 0: 84.53%\n",
    "* class 1: 15.47%\n",
    "\n",
    "Fore more information, click on detailed information from Prof. Jie Tao [link](https://github.com/DrJieTao/ba545-docs/blob/master/competition2/handling_imbalanced_data_part2.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (5958, 19)\n",
      "After OverSampling, the shape of train_y: (5958,) \n",
      "\n",
      "After OverSampling, counts of label '1': 993\n",
      "After OverSampling, counts of label '0': 993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=2019) \n",
    "\n",
    "sm = SMOTE(random_state = 2019) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train) \n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMOTE Algorithm has oversampled the instances in the minority class and made it equal to majority class:\n",
    "* Both classes (0 & 1) now have 7291 instances, the <b> training </b> dataset is balanced.\n",
    "* Class 1 increased from 1340 instances to 7291 instances, an increase of 5951 instances of class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.60      0.45        40\n",
      "           1       0.64      0.56      0.60       431\n",
      "           2       0.48      0.39      0.43       352\n",
      "           3       0.18      0.28      0.22        75\n",
      "           4       0.12      0.26      0.16        23\n",
      "           5       0.12      0.29      0.16        21\n",
      "\n",
      "    accuracy                           0.46       942\n",
      "   macro avg       0.32      0.40      0.34       942\n",
      "weighted avg       0.51      0.46      0.48       942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Using KFold </b>\n",
    "For more information on the topic, please click the following [link](https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/).\n",
    "<br> The details of the package are noted [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"12345\"> <h2> 1.2 Cross Validation (Oversampling)  </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "All the accuracy results:\n",
      "--------------------------------------------------------------------------\n",
      "[0.75167785 0.74832215 0.72147651 0.76006711 0.7533557  0.74496644\n",
      " 0.75       0.72986577 0.78319328 0.7512605 ] \n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Average of all the accuracy results:\n",
      "--------------------------------------------------------------------------\n",
      "0.7494 \n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Conclusion: the average of the accuracy changed after applying Kfold:\n",
      "--------------------------------------------------------------------------\n",
      "from:\n",
      "0.46178\n",
      "to:\n",
      "0.74942\n",
      "This is because we only use: 90.00% of our dataset to train the model!\n"
     ]
    }
   ],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(gnb, X, Y, cv=kfold, scoring='accuracy')\n",
    "result = cross_val_score(clf, X_train_res, y_train_res, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result.mean(), 4), '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Conclusion: the average of the accuracy changed after applying Kfold:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('from:')\n",
    "print(round(metrics.accuracy_score(y_test, y_pred), 5))\n",
    "print('to:')\n",
    "print(round(result.mean(), 5))\n",
    "print('This is because we only use: {0:0.2f}% of our dataset to train the model!'.format(((k_fold_split-1)/k_fold_split)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "All the weighted f1 results:\n",
      "--------------------------------------------------------------------------\n",
      "[0.73990512 0.74035919 0.71233377 0.7609838  0.74278282 0.75002915\n",
      " 0.74989434 0.72715726 0.76600333 0.74550212] \n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Average of all the weighted f1 results:\n",
      "--------------------------------------------------------------------------\n",
      "0.7435 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "# note: only a single metric is permitted for parameter 'scoring'\n",
    "# for all parameters for scoring, see source:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "result_f1_weighted = cross_val_score(clf, X_train_res, y_train_res, cv=kfold, scoring='f1_weighted')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result_f1_weighted, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result_f1_weighted.mean(), 4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"123456\"> <h2> 1.3 Cross Validation (Undersampling)  </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "All the accuracy results:\n",
      "--------------------------------------------------------------------------\n",
      "[0.46178344 0.49044586 0.44585987 0.50955414 0.45859873 0.43630573\n",
      " 0.44585987 0.49044586 0.43630573 0.46964856] \n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Average of all the accuracy results:\n",
      "--------------------------------------------------------------------------\n",
      "0.4645 \n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Conclusion: the average of the accuracy changed after applying Kfold:\n",
      "--------------------------------------------------------------------------\n",
      "from:\n",
      "0.46178\n",
      "to:\n",
      "0.46448\n",
      "This is because we only use: 90.00% of our dataset to train the model!\n"
     ]
    }
   ],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "#result = cross_val_score(clf, X_train_miss, y_train_miss, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result.mean(), 4), '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Conclusion: the average of the accuracy changed after applying Kfold:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('from:')\n",
    "print(round(metrics.accuracy_score(y_test, y_pred), 5))\n",
    "print('to:')\n",
    "print(round(result.mean(), 5))\n",
    "print('This is because we only use: {0:0.2f}% of our dataset to train the model!'.format(((k_fold_split-1)/k_fold_split)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "All the weighted f1 results:\n",
      "--------------------------------------------------------------------------\n",
      "[0.73990512 0.74035919 0.71233377 0.7609838  0.74278282 0.75002915\n",
      " 0.74989434 0.72715726 0.76600333 0.74550212] \n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Average of all the weighted f1 results:\n",
      "--------------------------------------------------------------------------\n",
      "0.7435 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "# note: only a single metric is permitted for parameter 'scoring'\n",
    "# for all parameters for scoring, see source:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "#result_f1_weighted = cross_val_score(clf, X_train_miss, y_train_miss, cv=kfold, scoring='f1_weighted')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result_f1_weighted, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result_f1_weighted.mean(), 4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"800150\"> <h2> 1.5 Model Tuning (Hyperparameters) </h2> </a>\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Define Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= ['gini', 'entropy'] \n",
    "splitter= ['best', 'random'] \n",
    "max_depth= [3,5,10] \n",
    "param_grid = dict(criterion=criterion, splitter=splitter, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Hyper-parameter tweaking on oversampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.668681 using {'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "--- Execution time: ---\n",
      "--- 3504.790ms. --- \n",
      "--- 3.5047903060913086 seconds ---\n",
      "--- 0.05841317176818848 minutes ---\n"
     ]
    }
   ],
   "source": [
    "# set the start time\n",
    "start = time.time()\n",
    "\n",
    "# define the model\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create a grid search object\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search (Fitting your model to the training data)\n",
    "grid_result = grid.fit(X_train_res, y_train_res)\n",
    "\n",
    "# define each optimal parameter as a new variable\n",
    "optimal_criterion = grid.best_estimator_.get_params()['criterion']\n",
    "optimal_splitter = grid.best_estimator_.get_params()['splitter']\n",
    "optimal_max_depth = grid.best_estimator_.get_params()['max_depth']\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# get the time it takes for the gridsearch to run\n",
    "# source: https://blog.softhints.com/python-test-performance-and-measure-time-elapsed-in-seconds/\n",
    "# set the end time\n",
    "end = time.time()\n",
    "\n",
    "# get the elapsed execution time\n",
    "execution_time = end - start\n",
    "print(\"--- Execution time: ---\")\n",
    "print ('--- %0.3fms. --- ' % ( execution_time*1000.))\n",
    "print(\"--- %s seconds ---\" % (execution_time))\n",
    "print(\"--- %s minutes ---\" % (execution_time/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Applying the optimal hyper-parameters on oversampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.34        40\n",
      "           1       0.64      0.54      0.59       431\n",
      "           2       0.48      0.30      0.37       352\n",
      "           3       0.17      0.33      0.23        75\n",
      "           4       0.06      0.17      0.09        23\n",
      "           5       0.10      0.29      0.15        21\n",
      "\n",
      "    accuracy                           0.42       942\n",
      "   macro avg       0.28      0.36      0.29       942\n",
      "weighted avg       0.50      0.42      0.44       942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply the optimal hyper-parameters to the Logistic Regression Model\n",
    "clf3 = DecisionTreeClassifier(criterion=optimal_criterion, splitter=optimal_splitter, max_depth=optimal_max_depth)\n",
    "\n",
    "# fit/train the model with oversampled training set\n",
    "clf3.fit(X_train_res, y_train_res)\n",
    "\n",
    "# predict the testing set\n",
    "y_pred=clf3.predict(X_test)\n",
    "\n",
    "# print out the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"1234567\"> <h2> 2.0 Basic Model Decision Tree Classifier 'Death Rate'</h2> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variable is 'Death Rate Categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"final_death_data.csv\")\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.iloc[:, :-1] # Features is all columns in the dataframe except the last column\n",
    "Y = df2.iloc[:, -1] # Target is the last column in the dataframe: 'Death Rate Categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf2 = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf2 = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4607218683651805\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65       390\n",
      "           1       0.37      0.39      0.38       203\n",
      "           2       0.33      0.36      0.35       228\n",
      "           3       0.23      0.18      0.20        89\n",
      "           4       0.12      0.11      0.12        27\n",
      "           5       0.25      0.40      0.31         5\n",
      "\n",
      "    accuracy                           0.46       942\n",
      "   macro avg       0.33      0.35      0.33       942\n",
      "weighted avg       0.46      0.46      0.46       942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[251  54  70  12   3   0]\n",
      " [ 44  79  59  15   5   1]\n",
      " [ 55  54  83  26   8   2]\n",
      " [ 22  21  23  16   6   1]\n",
      " [  6   4  11   1   3   2]\n",
      " [  0   0   3   0   0   2]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"12345678\"> <h2> 2.1 Oversampling (SMOTE) </h2> </a>\n",
    "We oversample the <b> training </b> dataset, because the classes within our target variable 'Revenue' are imbalanced:\n",
    "* class 0: 84.53%\n",
    "* class 1: 15.47%\n",
    "\n",
    "Fore more information, click on detailed information from Prof. Jie Tao [link](https://github.com/DrJieTao/ba545-docs/blob/master/competition2/handling_imbalanced_data_part2.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (5202, 20)\n",
      "After OverSampling, the shape of train_y: (5202,) \n",
      "\n",
      "After OverSampling, counts of label '1': 867\n",
      "After OverSampling, counts of label '0': 867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=2019) \n",
    "\n",
    "sm = SMOTE(random_state = 2019) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train) \n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMOTE Algorithm has oversampled the instances in the minority class and made it equal to majority class:\n",
    "* Both classes (0 & 1) now have 7291 instances, the <b> training </b> dataset is balanced.\n",
    "* Class 1 increased from 1340 instances to 7291 instances, an increase of 5951 instances of class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64       390\n",
      "           1       0.37      0.39      0.38       203\n",
      "           2       0.31      0.31      0.31       228\n",
      "           3       0.17      0.16      0.16        89\n",
      "           4       0.05      0.11      0.07        27\n",
      "           5       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.42       942\n",
      "   macro avg       0.26      0.26      0.26       942\n",
      "weighted avg       0.46      0.42      0.44       942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf2 = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf2 = clf2.fit(X_train_res, y_train_res)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf2.predict(X_test)\n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Using KFold </b>\n",
    "For more information on the topic, please click the following [link](https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/).\n",
    "<br> The details of the package are noted [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"123456789\"> <h2> 2.2 Cross Validation (Oversampling)  </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "All the accuracy results:\n",
      "--------------------------------------------------------------------------\n",
      "[0.72168906 0.66602687 0.73076923 0.74038462 0.71923077 0.69038462\n",
      " 0.69230769 0.70384615 0.71923077 0.71153846] \n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Average of all the accuracy results:\n",
      "--------------------------------------------------------------------------\n",
      "0.7095 \n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Conclusion: the average of the accuracy changed after applying Kfold:\n",
      "--------------------------------------------------------------------------\n",
      "from:\n",
      "0.42463\n",
      "to:\n",
      "0.70954\n",
      "This is because we only use: 90.00% of our dataset to train the model!\n"
     ]
    }
   ],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(gnb, X, Y, cv=kfold, scoring='accuracy')\n",
    "result = cross_val_score(clf, X_train_res, y_train_res, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result.mean(), 4), '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Conclusion: the average of the accuracy changed after applying Kfold:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('from:')\n",
    "print(round(metrics.accuracy_score(y_test, y_pred), 5))\n",
    "print('to:')\n",
    "print(round(result.mean(), 5))\n",
    "print('This is because we only use: {0:0.2f}% of our dataset to train the model!'.format(((k_fold_split-1)/k_fold_split)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "All the weighted f1 results:\n",
      "--------------------------------------------------------------------------\n",
      "[0.74115748 0.68317042 0.72982914 0.73576053 0.71780768 0.72596926\n",
      " 0.68062536 0.72788834 0.71029462 0.71679411] \n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Average of all the weighted f1 results:\n",
      "--------------------------------------------------------------------------\n",
      "0.7169 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "# note: only a single metric is permitted for parameter 'scoring'\n",
    "# for all parameters for scoring, see source:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "result_f1_weighted = cross_val_score(clf, X_train_res, y_train_res, cv=kfold, scoring='f1_weighted')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result_f1_weighted, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result_f1_weighted.mean(), 4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"1234567891\"> <h2> 2.3 Cross Validation (Undersampling)  </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "All the accuracy results:\n",
      "--------------------------------------------------------------------------\n",
      "[0.48089172 0.45541401 0.44585987 0.45859873 0.41082803 0.44585987\n",
      " 0.41719745 0.45859873 0.46178344 0.41533546] \n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Average of all the accuracy results:\n",
      "--------------------------------------------------------------------------\n",
      "0.445 \n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Conclusion: the average of the accuracy changed after applying Kfold:\n",
      "--------------------------------------------------------------------------\n",
      "from:\n",
      "0.42463\n",
      "to:\n",
      "0.44504\n",
      "This is because we only use: 90.00% of our dataset to train the model!\n"
     ]
    }
   ],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "result = cross_val_score(clf2, X, Y, cv=kfold, scoring='accuracy')\n",
    "#result = cross_val_score(clf2, X_train_miss, y_train_miss, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result.mean(), 4), '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Conclusion: the average of the accuracy changed after applying Kfold:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('from:')\n",
    "print(round(metrics.accuracy_score(y_test, y_pred), 5))\n",
    "print('to:')\n",
    "print(round(result.mean(), 5))\n",
    "print('This is because we only use: {0:0.2f}% of our dataset to train the model!'.format(((k_fold_split-1)/k_fold_split)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "All the weighted f1 results:\n",
      "--------------------------------------------------------------------------\n",
      "[0.74115748 0.68317042 0.72982914 0.73576053 0.71780768 0.72596926\n",
      " 0.68062536 0.72788834 0.71029462 0.71679411] \n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Average of all the weighted f1 results:\n",
      "--------------------------------------------------------------------------\n",
      "0.7169 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#esult = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "# note: only a single metric is permitted for parameter 'scoring'\n",
    "# for all parameters for scoring, see source:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "#result_f1_weighted = cross_val_score(clf2, X_train_miss, y_train_miss, cv=kfold, scoring='f1_weighted')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result_f1_weighted, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result_f1_weighted.mean(), 4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"12345678912\"> <h2> 2.4 Model Tuning (Hyperparameters) </h2> </a>\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Define Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= ['gini', 'entropy'] \n",
    "splitter= ['best', 'random'] \n",
    "max_depth= [3,5,10] \n",
    "param_grid = dict(criterion=criterion, splitter=splitter, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Hyper-parameter tweaking on oversampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.645905 using {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'best'}\n",
      "--- Execution time: ---\n",
      "--- 3470.572ms. --- \n",
      "--- 3.470571994781494 seconds ---\n",
      "--- 0.05784286657969157 minutes ---\n"
     ]
    }
   ],
   "source": [
    "# set the start time\n",
    "start = time.time()\n",
    "\n",
    "# define the model\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create a grid search object\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search (Fitting your model to the training data)\n",
    "grid_result = grid.fit(X_train_res, y_train_res)\n",
    "\n",
    "# define each optimal parameter as a new variable\n",
    "optimal_criterion = grid.best_estimator_.get_params()['criterion']\n",
    "optimal_splitter = grid.best_estimator_.get_params()['splitter']\n",
    "optimal_max_depth = grid.best_estimator_.get_params()['max_depth']\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# get the time it takes for the gridsearch to run\n",
    "# source: https://blog.softhints.com/python-test-performance-and-measure-time-elapsed-in-seconds/\n",
    "# set the end time\n",
    "end = time.time()\n",
    "\n",
    "# get the elapsed execution time\n",
    "execution_time = end - start\n",
    "print(\"--- Execution time: ---\")\n",
    "print ('--- %0.3fms. --- ' % ( execution_time*1000.))\n",
    "print(\"--- %s seconds ---\" % (execution_time))\n",
    "print(\"--- %s minutes ---\" % (execution_time/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Applying the optimal hyper-parameters on oversampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.60      0.66       390\n",
      "           1       0.37      0.43      0.40       203\n",
      "           2       0.28      0.22      0.25       228\n",
      "           3       0.15      0.20      0.17        89\n",
      "           4       0.09      0.22      0.13        27\n",
      "           5       0.10      0.20      0.13         5\n",
      "\n",
      "    accuracy                           0.42       942\n",
      "   macro avg       0.28      0.31      0.29       942\n",
      "weighted avg       0.46      0.42      0.44       942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply the optimal hyper-parameters to the Logistic Regression Model\n",
    "clf3 = DecisionTreeClassifier(criterion=optimal_criterion, splitter=optimal_splitter, max_depth=optimal_max_depth)\n",
    "\n",
    "# fit/train the model with oversampled training set\n",
    "clf3.fit(X_train_res, y_train_res)\n",
    "\n",
    "# predict the testing set\n",
    "y_pred=clf3.predict(X_test)\n",
    "\n",
    "# print out the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
