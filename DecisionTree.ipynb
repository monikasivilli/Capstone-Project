{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree, metrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss \n",
    "\n",
    "# Cross Validation packages\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# import module for gridsearch (to find optimal hyper-parameters)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import module (to test execution time of a codeblock to run)\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "# packages for Receiver Operating Characteristic (ROC) with cross validation\n",
    "# source: https://scikit-learn.org/0.18/auto_examples/model_selection/plot_roc_crossval.html\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data before Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"census_covid_cat_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Name</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>State</th>\n",
       "      <th>State Abbr</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Households SNAP</th>\n",
       "      <th>Estimated Individuals SNAP</th>\n",
       "      <th>Total Citizen Educated in US</th>\n",
       "      <th>Citizen Less than High School  Education</th>\n",
       "      <th>Citizen High School  Graduate</th>\n",
       "      <th>...</th>\n",
       "      <th>Female Median Age</th>\n",
       "      <th>Total Households</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>Total Families</th>\n",
       "      <th>Total Confirmed Cases</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Case Rate per 1000</th>\n",
       "      <th>Death Rate 1000</th>\n",
       "      <th>Case Rate Categories</th>\n",
       "      <th>Death Rate Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autauga County, Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>54571</td>\n",
       "      <td>2802</td>\n",
       "      <td>7509</td>\n",
       "      <td>36757</td>\n",
       "      <td>4521</td>\n",
       "      <td>12363</td>\n",
       "      <td>...</td>\n",
       "      <td>37.9</td>\n",
       "      <td>20221</td>\n",
       "      <td>3</td>\n",
       "      <td>14613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.330</td>\n",
       "      <td>0.147</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldwin County, Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>182265</td>\n",
       "      <td>6644</td>\n",
       "      <td>16344</td>\n",
       "      <td>143022</td>\n",
       "      <td>13997</td>\n",
       "      <td>39771</td>\n",
       "      <td>...</td>\n",
       "      <td>42.2</td>\n",
       "      <td>73180</td>\n",
       "      <td>2</td>\n",
       "      <td>41898</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>2.200</td>\n",
       "      <td>0.049</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barbour County, Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>27457</td>\n",
       "      <td>2468</td>\n",
       "      <td>6096</td>\n",
       "      <td>18434</td>\n",
       "      <td>4960</td>\n",
       "      <td>6549</td>\n",
       "      <td>...</td>\n",
       "      <td>41.6</td>\n",
       "      <td>9820</td>\n",
       "      <td>2</td>\n",
       "      <td>6015</td>\n",
       "      <td>401</td>\n",
       "      <td>9</td>\n",
       "      <td>9.579</td>\n",
       "      <td>0.036</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bibb County, Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>22915</td>\n",
       "      <td>933</td>\n",
       "      <td>2426</td>\n",
       "      <td>15859</td>\n",
       "      <td>2833</td>\n",
       "      <td>6958</td>\n",
       "      <td>...</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7953</td>\n",
       "      <td>3</td>\n",
       "      <td>5201</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>5.280</td>\n",
       "      <td>0.044</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blount County, Alabama</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>57322</td>\n",
       "      <td>2244</td>\n",
       "      <td>5902</td>\n",
       "      <td>39475</td>\n",
       "      <td>7980</td>\n",
       "      <td>12740</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21578</td>\n",
       "      <td>3</td>\n",
       "      <td>14106</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>2.268</td>\n",
       "      <td>0.017</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Full Name    Country Name    State State Abbr  \\\n",
       "0  Autauga County, Alabama  Autauga County  Alabama         AL   \n",
       "1  Baldwin County, Alabama  Baldwin County  Alabama         AL   \n",
       "2  Barbour County, Alabama  Barbour County  Alabama         AL   \n",
       "3     Bibb County, Alabama     Bibb County  Alabama         AL   \n",
       "4   Blount County, Alabama   Blount County  Alabama         AL   \n",
       "\n",
       "    Total Population    Households SNAP    Estimated Individuals SNAP   \\\n",
       "0               54571               2802                          7509   \n",
       "1              182265               6644                         16344   \n",
       "2               27457               2468                          6096   \n",
       "3               22915                933                          2426   \n",
       "4               57322               2244                          5902   \n",
       "\n",
       "    Total Citizen Educated in US    Citizen Less than High School  Education   \\\n",
       "0                           36757                                        4521   \n",
       "1                          143022                                       13997   \n",
       "2                           18434                                        4960   \n",
       "3                           15859                                        2833   \n",
       "4                           39475                                        7980   \n",
       "\n",
       "    Citizen High School  Graduate   ...  Female Median Age  \\\n",
       "0                            12363  ...               37.9   \n",
       "1                            39771  ...               42.2   \n",
       "2                             6549  ...               41.6   \n",
       "3                             6958  ...               39.5   \n",
       "4                            12740  ...               40.0   \n",
       "\n",
       "    Total Households    Average Household Size    Total Families   \\\n",
       "0               20221                         3             14613   \n",
       "1               73180                         2             41898   \n",
       "2                9820                         2              6015   \n",
       "3                7953                         3              5201   \n",
       "4               21578                         3             14106   \n",
       "\n",
       "   Total Confirmed Cases  Total Deaths  Case Rate per 1000  Death Rate 1000  \\\n",
       "0                      0             0               7.330            0.147   \n",
       "1                    400             8               2.200            0.049   \n",
       "2                    401             9               9.579            0.036   \n",
       "3                    263             1               5.280            0.044   \n",
       "4                    121             1               2.268            0.017   \n",
       "\n",
       "   Case Rate Categories   Death Rate Categories  \n",
       "0                      2                      2  \n",
       "1                      2                      1  \n",
       "2                      3                      1  \n",
       "3                      2                      1  \n",
       "4                      2                      1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Full Name                                      object\n",
       "Country Name                                   object\n",
       "State                                          object\n",
       "State Abbr                                     object\n",
       " Total Population                               int64\n",
       " Households SNAP                                int64\n",
       " Estimated Individuals SNAP                     int64\n",
       " Total Citizen Educated in US                   int64\n",
       " Citizen Less than High School  Education       int64\n",
       " Citizen High School  Graduate                  int64\n",
       " Citizen Some College  Education                int64\n",
       " Citizen College Degree                         int64\n",
       " Citizen Graduate or Professional Degree        int64\n",
       " Total Citizen Income                           int64\n",
       " Citizen No Income                              int64\n",
       "Citizen Income 1-9999                           int64\n",
       "Citizen Income 10000-14999                      int64\n",
       "Citizen Income 15000-24999                      int64\n",
       "Citizen Income 25000-34999                      int64\n",
       "Citizen Income 35000-49999                      int64\n",
       "Citizen Income 50000-64999                      int64\n",
       "Citizen Income 65000-74999                      int64\n",
       "Citizen Income over 75000                       int64\n",
       " One Race Population                            int64\n",
       " White Race                                     int64\n",
       " Black Race                                     int64\n",
       " Native American Race                           int64\n",
       " Asian Race                                     int64\n",
       " Pacific Islander Race                          int64\n",
       " Other Race Alone                               int64\n",
       " Hispanic or Latino                             int64\n",
       "Median Age                                    float64\n",
       "Male Median Age                               float64\n",
       "Female Median Age                             float64\n",
       " Total Households                               int64\n",
       " Average Household Size                         int64\n",
       " Total Families                                 int64\n",
       "Total Confirmed Cases                           int64\n",
       "Total Deaths                                    int64\n",
       "Case Rate per 1000                            float64\n",
       "Death Rate 1000                               float64\n",
       "Case Rate Categories                            int64\n",
       "Death Rate Categories                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the spaces of the cells from the csv file\n",
    "df.columns = df.columns.to_series().apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to change int64 to cat type for target vars\n",
    "df['Case Rate Categories'] = df['Case Rate Categories'].astype('category')\n",
    "df['Death Rate Categories'] = df['Death Rate Categories'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes\n",
    "#check to see if types changed to cat -- YES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"\"> <h2> 1.0 Basic Model Decision Tree Classifier </h2> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Build the Model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variable is 'Death Rate Categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these features to normalized ones \n",
    "features = ['Total Population','Households SNAP','Estimated Individuals SNAP','Total Citizen Educated in US',\n",
    "                       'Citizen Less than High School  Education','Citizen High School  Graduate',\n",
    "                       'Citizen Some College  Education','Citizen College Degree','Citizen Graduate or Professional Degree',\n",
    "                       'Total Citizen Income','Citizen No Income','Citizen Income 1-9999','Citizen Income 10000-14999',\n",
    "                       'Citizen Income 15000-24999','Citizen Income 25000-34999','Citizen Income 35000-49999',\n",
    "                       'Citizen Income 50000-64999','Citizen Income 65000-74999','Citizen Income over 75000',\n",
    "                       'One Race Population','White Race','Black Race','Native American Race','Asian Race',\n",
    "                       'Pacific Islander Race','Other Race Alone','Hispanic or Latino','Median Age', \n",
    "                        'Male Median Age','Female Median Age','Total Households',\n",
    "                       'Average Household Size','Total Families']\n",
    "\n",
    "X = df[features] # from list above\n",
    "Y = df.iloc[:, -1] # Target is the last column in the dataframe: ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['Case Rate Categories'], axis=1)\n",
    "#df1.head() check to see if the column was dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43312101910828027\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.61      0.64       390\n",
      "           1       0.36      0.42      0.39       203\n",
      "           2       0.29      0.29      0.29       228\n",
      "           3       0.18      0.19      0.19        89\n",
      "           4       0.07      0.07      0.07        27\n",
      "           5       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.43       942\n",
      "   macro avg       0.26      0.26      0.26       942\n",
      "weighted avg       0.45      0.43      0.44       942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[238  58  72  15   6   1]\n",
      " [ 40  85  53  22   2   1]\n",
      " [ 51  65  66  31  12   3]\n",
      " [ 20  23  22  17   7   0]\n",
      " [  7   5   8   5   2   0]\n",
      " [  0   0   3   2   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Graph of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2dd2e2e65e5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m export_graphviz(clf, out_file=dot_data,  \n\u001b[1;32m      7\u001b[0m                 \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 special_characters=True, feature_names = features,class_names=['0','1'])\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'covid_census.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrounded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_characters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecial_characters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             precision=precision)\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mexporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, decision_tree)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             self.recurse(decision_tree.tree_, 0,\n\u001b[0;32m--> 407\u001b[0;31m                          criterion=decision_tree.criterion)\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    491\u001b[0m                              parent=node_id, depth=depth + 1)\n\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[0;32m--> 493\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    465\u001b[0m             self.out_file.write(\n\u001b[1;32m    466\u001b[0m                 '%d [label=%s' % (node_id, self.node_to_str(tree, node_id,\n\u001b[0;32m--> 467\u001b[0;31m                                                             criterion)))\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mnode_to_str\u001b[0;34m(self, tree, node_id, criterion)\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0mnode_string\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'class = '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                 \u001b[0mclass_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 class_name = \"y%s%s%s\" % (characters[1],\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# source: https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names = features,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('covid_census.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"800110\"> <h2> 1.1 Oversampling (SMOTE) </h2> </a>\n",
    "We oversample the <b> training </b> dataset, because the classes within our target variable 'Revenue' are imbalanced:\n",
    "* class 0: 84.53%\n",
    "* class 1: 15.47%\n",
    "\n",
    "Fore more information, click on detailed information from Prof. Jie Tao [link](https://github.com/DrJieTao/ba545-docs/blob/master/competition2/handling_imbalanced_data_part2.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=2019) \n",
    "\n",
    "sm = SMOTE(random_state = 2019) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train) \n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMOTE Algorithm has oversampled the instances in the minority class and made it equal to majority class:\n",
    "* Both classes (0 & 1) now have 7291 instances, the <b> training </b> dataset is balanced.\n",
    "* Class 1 increased from 1340 instances to 7291 instances, an increase of 5951 instances of class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Using KFold </b>\n",
    "For more information on the topic, please click the following [link](https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/).\n",
    "<br> The details of the package are noted [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"800130\"> <h2> 1.3 Cross Validation (Oversampling)  </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(gnb, X, Y, cv=kfold, scoring='accuracy')\n",
    "result = cross_val_score(clf, X_train_res, y_train_res, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result.mean(), 4), '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Conclusion: the average of the accuracy changed after applying Kfold:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('from:')\n",
    "print(round(metrics.accuracy_score(y_test, y_pred), 5))\n",
    "print('to:')\n",
    "print(round(result.mean(), 5))\n",
    "print('This is because we only use: {0:0.2f}% of our dataset to train the model!'.format(((k_fold_split-1)/k_fold_split)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "# note: only a single metric is permitted for parameter 'scoring'\n",
    "# for all parameters for scoring, see source:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "result_f1_weighted = cross_val_score(clf, X_train_res, y_train_res, cv=kfold, scoring='f1_weighted')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result_f1_weighted, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result_f1_weighted.mean(), 4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"800140\"> <h2> 1.4 Cross Validation (Undersampling)  </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "result = cross_val_score(clf2, X_train_miss, y_train_miss, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result.mean(), 4), '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Conclusion: the average of the accuracy changed after applying Kfold:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('from:')\n",
    "print(round(metrics.accuracy_score(y_test, y_pred), 5))\n",
    "print('to:')\n",
    "print(round(result.mean(), 5))\n",
    "print('This is because we only use: {0:0.2f}% of our dataset to train the model!'.format(((k_fold_split-1)/k_fold_split)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "# note: only a single metric is permitted for parameter 'scoring'\n",
    "# for all parameters for scoring, see source:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "result_f1_weighted = cross_val_score(clf2, X_train_miss, y_train_miss, cv=kfold, scoring='f1_weighted')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result_f1_weighted, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result_f1_weighted.mean(), 4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"800150\"> <h2> 1.5 Model Tuning (Hyperparameters) </h2> </a>\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Define Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= ['gini', 'entropy'] \n",
    "splitter= ['best', 'random'] \n",
    "max_depth= [3,5,10] \n",
    "param_grid = dict(criterion=criterion, splitter=splitter, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Hyper-parameter tweaking on oversampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the start time\n",
    "start = time.time()\n",
    "\n",
    "# define the model\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create a grid search object\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search (Fitting your model to the training data)\n",
    "grid_result = grid.fit(X_train_res, y_train_res)\n",
    "\n",
    "# define each optimal parameter as a new variable\n",
    "optimal_criterion = grid.best_estimator_.get_params()['criterion']\n",
    "optimal_splitter = grid.best_estimator_.get_params()['splitter']\n",
    "optimal_max_depth = grid.best_estimator_.get_params()['max_depth']\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# get the time it takes for the gridsearch to run\n",
    "# source: https://blog.softhints.com/python-test-performance-and-measure-time-elapsed-in-seconds/\n",
    "# set the end time\n",
    "end = time.time()\n",
    "\n",
    "# get the elapsed execution time\n",
    "execution_time = end - start\n",
    "print(\"--- Execution time: ---\")\n",
    "print ('--- %0.3fms. --- ' % ( execution_time*1000.))\n",
    "print(\"--- %s seconds ---\" % (execution_time))\n",
    "print(\"--- %s minutes ---\" % (execution_time/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Applying the optimal hyper-parameters on oversampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the optimal hyper-parameters to the Logistic Regression Model\n",
    "clf3 = DecisionTreeClassifier(criterion=optimal_criterion, splitter=optimal_splitter, max_depth=optimal_max_depth)\n",
    "\n",
    "# fit/train the model with oversampled training set\n",
    "clf3.fit(X_train_res, y_train_res)\n",
    "\n",
    "# predict the testing set\n",
    "y_pred=clf3.predict(X_test)\n",
    "\n",
    "# print out the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variable is 'Case Rate Categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"census_covid_cat_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Death Rate Categories -- need Case Rate Categories to be the target variable\n",
    "df2 = df.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.iloc[:, 4:-7] # Features is all columns in the dataframe except the last 6 columns\n",
    "Y = df2.iloc[:, -1] # Target is the last column in the dataframe: 'Case Rate Categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"800110\"> <h2> 1.1 Oversampling (SMOTE) </h2> </a>\n",
    "We oversample the <b> training </b> dataset, because the classes within our target variable 'Revenue' are imbalanced:\n",
    "* class 0: 84.53%\n",
    "* class 1: 15.47%\n",
    "\n",
    "Fore more information, click on detailed information from Prof. Jie Tao [link](https://github.com/DrJieTao/ba545-docs/blob/master/competition2/handling_imbalanced_data_part2.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=2019) \n",
    "\n",
    "sm = SMOTE(random_state = 2019) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train) \n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMOTE Algorithm has oversampled the instances in the minority class and made it equal to majority class:\n",
    "* Both classes (0 & 1) now have 7291 instances, the <b> training </b> dataset is balanced.\n",
    "* Class 1 increased from 1340 instances to 7291 instances, an increase of 5951 instances of class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Using KFold </b>\n",
    "For more information on the topic, please click the following [link](https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/).\n",
    "<br> The details of the package are noted [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"800130\"> <h2> 1.3 Cross Validation (Oversampling)  </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(gnb, X, Y, cv=kfold, scoring='accuracy')\n",
    "result = cross_val_score(clf, X_train_res, y_train_res, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result.mean(), 4), '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Conclusion: the average of the accuracy changed after applying Kfold:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('from:')\n",
    "print(round(metrics.accuracy_score(y_test, y_pred), 5))\n",
    "print('to:')\n",
    "print(round(result.mean(), 5))\n",
    "print('This is because we only use: {0:0.2f}% of our dataset to train the model!'.format(((k_fold_split-1)/k_fold_split)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "# note: only a single metric is permitted for parameter 'scoring'\n",
    "# for all parameters for scoring, see source:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "result_f1_weighted = cross_val_score(clf, X_train_res, y_train_res, cv=kfold, scoring='f1_weighted')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result_f1_weighted, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result_f1_weighted.mean(), 4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"800140\"> <h2> 1.4 Cross Validation (Undersampling)  </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "result = cross_val_score(clf2, X_train_miss, y_train_miss, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result.mean(), 4), '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Conclusion: the average of the accuracy changed after applying Kfold:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('from:')\n",
    "print(round(metrics.accuracy_score(y_test, y_pred), 5))\n",
    "print('to:')\n",
    "print(round(result.mean(), 5))\n",
    "print('This is because we only use: {0:0.2f}% of our dataset to train the model!'.format(((k_fold_split-1)/k_fold_split)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "# note: only a single metric is permitted for parameter 'scoring'\n",
    "# for all parameters for scoring, see source:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "result_f1_weighted = cross_val_score(clf2, X_train_miss, y_train_miss, cv=kfold, scoring='f1_weighted')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result_f1_weighted, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result_f1_weighted.mean(), 4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"800150\"> <h2> 1.5 Model Tuning (Hyperparameters) </h2> </a>\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Define Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= ['gini', 'entropy'] \n",
    "splitter= ['best', 'random'] \n",
    "max_depth= [3,5,10] \n",
    "param_grid = dict(criterion=criterion, splitter=splitter, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Hyper-parameter tweaking on oversampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the start time\n",
    "start = time.time()\n",
    "\n",
    "# define the model\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create a grid search object\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search (Fitting your model to the training data)\n",
    "grid_result = grid.fit(X_train_res, y_train_res)\n",
    "\n",
    "# define each optimal parameter as a new variable\n",
    "optimal_criterion = grid.best_estimator_.get_params()['criterion']\n",
    "optimal_splitter = grid.best_estimator_.get_params()['splitter']\n",
    "optimal_max_depth = grid.best_estimator_.get_params()['max_depth']\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# get the time it takes for the gridsearch to run\n",
    "# source: https://blog.softhints.com/python-test-performance-and-measure-time-elapsed-in-seconds/\n",
    "# set the end time\n",
    "end = time.time()\n",
    "\n",
    "# get the elapsed execution time\n",
    "execution_time = end - start\n",
    "print(\"--- Execution time: ---\")\n",
    "print ('--- %0.3fms. --- ' % ( execution_time*1000.))\n",
    "print(\"--- %s seconds ---\" % (execution_time))\n",
    "print(\"--- %s minutes ---\" % (execution_time/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Applying the optimal hyper-parameters on oversampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the optimal hyper-parameters to the Logistic Regression Model\n",
    "clf3 = DecisionTreeClassifier(criterion=optimal_criterion, splitter=optimal_splitter, max_depth=optimal_max_depth)\n",
    "\n",
    "# fit/train the model with oversampled training set\n",
    "clf3.fit(X_train_res, y_train_res)\n",
    "\n",
    "# predict the testing set\n",
    "y_pred=clf3.predict(X_test)\n",
    "\n",
    "# print out the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
