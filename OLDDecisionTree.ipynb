{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Table of Contents: </b>\n",
    "<b> Target Variable: Death Rate Categories </b>\n",
    "<br> [1.0 Basic Model Decision Tree Classifier - Death Rate](#123)\n",
    "        <br> [1.1 Oversampling (SMOTE)](#1234)\n",
    "        <br> [1.2 Cross Validation (Oversampling)](#12345)\n",
    "        <br> [1.3 Cross Validation (Undersampling)](#123456)\n",
    "<br> [2.0 Basic Model Decision Tree Classifier - Case Rate](#1234567)\n",
    "        <br> [2.1 Oversampling (SMOTE)](#12345678)\n",
    "        <br> [2.2 Cross Validation (Oversampling)](#123456789)\n",
    "        <br> [2.3 Cross Validation (Undersampling)](#1234567891)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree, metrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss \n",
    "\n",
    "# Cross Validation packages\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# import module for gridsearch (to find optimal hyper-parameters)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import module (to test execution time of a codeblock to run)\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "# packages for Receiver Operating Characteristic (ROC) with cross validation\n",
    "# source: https://scikit-learn.org/0.18/auto_examples/model_selection/plot_roc_crossval.html\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data before Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"census_covid_cat_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame (df, columns = ['Total Population_iqr_bc',\n",
    "                        'Total Citizen Educated in US_iqr_bc','Citizen Less than High School  Education_iqr_bc',\n",
    "                        'Citizen High School  Graduate_iqr_bc','Citizen Some College  Education_iqr_bc',\n",
    "                         'Citizen College Degree_iqr_bc','Total Citizen Income_iqr_bc','Citizen No Income_iqr_bc',\n",
    "                          'Citizen Income 1-9999_iqr_bc','Citizen Income 10000-14999_iqr_bc','Citizen Income 15000-24999_iqr_bc',\n",
    "                         'Citizen Income 25000-34999_iqr_bc','Citizen Income 35000-49999_iqr_bc',\n",
    "                        'Citizen Income 50000-64999_iqr_bc','Citizen Income over 75000_iqr_bc',\n",
    "                        'Hispanic or Latino_iqr_bc','Median Age_iqr_bc',\n",
    "                         'Male Median Age_iqr_bc', 'Female Median Age_iqr_bc',\n",
    "                       'Average Household Size_iqr_bc','Total Confirmed Cases', 'Total Deaths',\n",
    "                      'Case Rate per 1000', 'Death Rate 1000','Case Rate Categories', 'Death Rate Categories'] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Population_iqr_bc</th>\n",
       "      <th>Total Citizen Educated in US_iqr_bc</th>\n",
       "      <th>Citizen Less than High School  Education_iqr_bc</th>\n",
       "      <th>Citizen High School  Graduate_iqr_bc</th>\n",
       "      <th>Citizen Some College  Education_iqr_bc</th>\n",
       "      <th>Citizen College Degree_iqr_bc</th>\n",
       "      <th>Total Citizen Income_iqr_bc</th>\n",
       "      <th>Citizen No Income_iqr_bc</th>\n",
       "      <th>Citizen Income 1-9999_iqr_bc</th>\n",
       "      <th>Citizen Income 10000-14999_iqr_bc</th>\n",
       "      <th>...</th>\n",
       "      <th>Median Age_iqr_bc</th>\n",
       "      <th>Male Median Age_iqr_bc</th>\n",
       "      <th>Female Median Age_iqr_bc</th>\n",
       "      <th>Average Household Size_iqr_bc</th>\n",
       "      <th>Total Confirmed Cases</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Case Rate per 1000</th>\n",
       "      <th>Death Rate 1000</th>\n",
       "      <th>Case Rate Categories</th>\n",
       "      <th>Death Rate Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.330</td>\n",
       "      <td>0.147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>2.200</td>\n",
       "      <td>0.049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>401</td>\n",
       "      <td>9</td>\n",
       "      <td>9.579</td>\n",
       "      <td>0.036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>5.280</td>\n",
       "      <td>0.044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>2.268</td>\n",
       "      <td>0.017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Population_iqr_bc  Total Citizen Educated in US_iqr_bc  \\\n",
       "0                      NaN                                  NaN   \n",
       "1                      NaN                                  NaN   \n",
       "2                      NaN                                  NaN   \n",
       "3                      NaN                                  NaN   \n",
       "4                      NaN                                  NaN   \n",
       "\n",
       "   Citizen Less than High School  Education_iqr_bc  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "\n",
       "   Citizen High School  Graduate_iqr_bc  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2                                   NaN   \n",
       "3                                   NaN   \n",
       "4                                   NaN   \n",
       "\n",
       "   Citizen Some College  Education_iqr_bc  Citizen College Degree_iqr_bc  \\\n",
       "0                                     NaN                            NaN   \n",
       "1                                     NaN                            NaN   \n",
       "2                                     NaN                            NaN   \n",
       "3                                     NaN                            NaN   \n",
       "4                                     NaN                            NaN   \n",
       "\n",
       "   Total Citizen Income_iqr_bc  Citizen No Income_iqr_bc  \\\n",
       "0                          NaN                       NaN   \n",
       "1                          NaN                       NaN   \n",
       "2                          NaN                       NaN   \n",
       "3                          NaN                       NaN   \n",
       "4                          NaN                       NaN   \n",
       "\n",
       "   Citizen Income 1-9999_iqr_bc  Citizen Income 10000-14999_iqr_bc  ...  \\\n",
       "0                           NaN                                NaN  ...   \n",
       "1                           NaN                                NaN  ...   \n",
       "2                           NaN                                NaN  ...   \n",
       "3                           NaN                                NaN  ...   \n",
       "4                           NaN                                NaN  ...   \n",
       "\n",
       "   Median Age_iqr_bc  Male Median Age_iqr_bc  Female Median Age_iqr_bc  \\\n",
       "0                NaN                     NaN                       NaN   \n",
       "1                NaN                     NaN                       NaN   \n",
       "2                NaN                     NaN                       NaN   \n",
       "3                NaN                     NaN                       NaN   \n",
       "4                NaN                     NaN                       NaN   \n",
       "\n",
       "   Average Household Size_iqr_bc  Total Confirmed Cases  Total Deaths  \\\n",
       "0                            NaN                      0             0   \n",
       "1                            NaN                    400             8   \n",
       "2                            NaN                    401             9   \n",
       "3                            NaN                    263             1   \n",
       "4                            NaN                    121             1   \n",
       "\n",
       "   Case Rate per 1000  Death Rate 1000  Case Rate Categories  \\\n",
       "0               7.330            0.147                   NaN   \n",
       "1               2.200            0.049                   NaN   \n",
       "2               9.579            0.036                   NaN   \n",
       "3               5.280            0.044                   NaN   \n",
       "4               2.268            0.017                   NaN   \n",
       "\n",
       "   Death Rate Categories  \n",
       "0                      2  \n",
       "1                      1  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Full Name                                      object\n",
       "Country Name                                   object\n",
       "State                                          object\n",
       "State Abbr                                     object\n",
       " Total Population                               int64\n",
       " Households SNAP                                int64\n",
       " Estimated Individuals SNAP                     int64\n",
       " Total Citizen Educated in US                   int64\n",
       " Citizen Less than High School  Education       int64\n",
       " Citizen High School  Graduate                  int64\n",
       " Citizen Some College  Education                int64\n",
       " Citizen College Degree                         int64\n",
       " Citizen Graduate or Professional Degree        int64\n",
       " Total Citizen Income                           int64\n",
       " Citizen No Income                              int64\n",
       "Citizen Income 1-9999                           int64\n",
       "Citizen Income 10000-14999                      int64\n",
       "Citizen Income 15000-24999                      int64\n",
       "Citizen Income 25000-34999                      int64\n",
       "Citizen Income 35000-49999                      int64\n",
       "Citizen Income 50000-64999                      int64\n",
       "Citizen Income 65000-74999                      int64\n",
       "Citizen Income over 75000                       int64\n",
       " One Race Population                            int64\n",
       " White Race                                     int64\n",
       " Black Race                                     int64\n",
       " Native American Race                           int64\n",
       " Asian Race                                     int64\n",
       " Pacific Islander Race                          int64\n",
       " Other Race Alone                               int64\n",
       " Hispanic or Latino                             int64\n",
       "Median Age                                    float64\n",
       "Male Median Age                               float64\n",
       "Female Median Age                             float64\n",
       " Total Households                               int64\n",
       " Average Household Size                         int64\n",
       " Total Families                                 int64\n",
       "Total Confirmed Cases                           int64\n",
       "Total Deaths                                    int64\n",
       "Case Rate per 1000                            float64\n",
       "Death Rate 1000                               float64\n",
       "Case Rate Categories                            int64\n",
       "Death Rate Categories                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the spaces of the cells from the csv file\n",
    "df.columns = df.columns.to_series().apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to change int64 to cat type for target vars\n",
    "df['Case Rate Categories'] = df['Case Rate Categories'].astype('category')\n",
    "df['Death Rate Categories'] = df['Death Rate Categories'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes\n",
    "#check to see if types changed to cat -- YES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"123\"> <h2> 1.0 Basic Model Decision Tree Classifier </h2> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Build the Model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variable is 'Death Rate Categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these features to normalized ones \n",
    "features = ['Total Population','Households SNAP','Estimated Individuals SNAP','Total Citizen Educated in US',\n",
    "                       'Citizen Less than High School  Education','Citizen High School  Graduate',\n",
    "                       'Citizen Some College  Education','Citizen College Degree','Citizen Graduate or Professional Degree',\n",
    "                       'Total Citizen Income','Citizen No Income','Citizen Income 1-9999','Citizen Income 10000-14999',\n",
    "                       'Citizen Income 15000-24999','Citizen Income 25000-34999','Citizen Income 35000-49999',\n",
    "                       'Citizen Income 50000-64999','Citizen Income 65000-74999','Citizen Income over 75000',\n",
    "                       'One Race Population','White Race','Black Race','Native American Race','Asian Race',\n",
    "                       'Pacific Islander Race','Other Race Alone','Hispanic or Latino','Median Age', \n",
    "                        'Male Median Age','Female Median Age','Total Households',\n",
    "                       'Average Household Size','Total Families']\n",
    "\n",
    "X = df[features] # from list above\n",
    "Y = df.iloc[:, -1] # Target is the last column in the dataframe: ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['Case Rate Categories'], axis=1)\n",
    "#df1.head() check to see if the column was dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4394904458598726\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.64       390\n",
      "           1       0.34      0.42      0.38       203\n",
      "           2       0.30      0.31      0.30       228\n",
      "           3       0.22      0.19      0.20        89\n",
      "           4       0.06      0.04      0.04        27\n",
      "           5       0.20      0.20      0.20         5\n",
      "\n",
      "    accuracy                           0.44       942\n",
      "   macro avg       0.30      0.30      0.30       942\n",
      "weighted avg       0.45      0.44      0.44       942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239  69  67  11   3   1]\n",
      " [ 41  86  57  16   3   0]\n",
      " [ 47  71  70  29   8   3]\n",
      " [ 20  23  26  17   3   0]\n",
      " [  6   5  10   5   1   0]\n",
      " [  0   0   3   1   0   1]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Graph of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a12588373f04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m export_graphviz(clf, out_file=dot_data,  \n\u001b[1;32m      8\u001b[0m                 \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 special_characters=True, feature_names = features,class_names=['0','1'])\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'covid_census.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrounded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_characters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecial_characters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             precision=precision)\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mexporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, decision_tree)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             self.recurse(decision_tree.tree_, 0,\n\u001b[0;32m--> 407\u001b[0;31m                          criterion=decision_tree.criterion)\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_child\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREE_LEAF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 self.recurse(tree, left_child, criterion=criterion,\n\u001b[0;32m--> 491\u001b[0;31m                              parent=node_id, depth=depth + 1)\n\u001b[0m\u001b[1;32m    492\u001b[0m                 self.recurse(tree, right_child, criterion=criterion,\n\u001b[1;32m    493\u001b[0m                              parent=node_id, depth=depth + 1)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(self, tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    465\u001b[0m             self.out_file.write(\n\u001b[1;32m    466\u001b[0m                 '%d [label=%s' % (node_id, self.node_to_str(tree, node_id,\n\u001b[0;32m--> 467\u001b[0;31m                                                             criterion)))\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mnode_to_str\u001b[0;34m(self, tree, node_id, criterion)\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0mnode_string\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'class = '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                 \u001b[0mclass_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 class_name = \"y%s%s%s\" % (characters[1],\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# source: https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names = features,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('covid_census.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"1234\"> <h2> 1.1 Oversampling (SMOTE) </h2> </a>\n",
    "We oversample the <b> training </b> dataset, because the classes within our target variable 'Revenue' are imbalanced:\n",
    "* class 0: 84.53%\n",
    "* class 1: 15.47%\n",
    "\n",
    "Fore more information, click on detailed information from Prof. Jie Tao [link](https://github.com/DrJieTao/ba545-docs/blob/master/competition2/handling_imbalanced_data_part2.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=2019) \n",
    "\n",
    "sm = SMOTE(random_state = 2019) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train) \n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMOTE Algorithm has oversampled the instances in the minority class and made it equal to majority class:\n",
    "* Both classes (0 & 1) now have 7291 instances, the <b> training </b> dataset is balanced.\n",
    "* Class 1 increased from 1340 instances to 7291 instances, an increase of 5951 instances of class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Using KFold </b>\n",
    "For more information on the topic, please click the following [link](https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/).\n",
    "<br> The details of the package are noted [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"12345\"> <h2> 1.2 Cross Validation (Oversampling)  </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(gnb, X, Y, cv=kfold, scoring='accuracy')\n",
    "result = cross_val_score(clf, X_train_res, y_train_res, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result.mean(), 4), '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Conclusion: the average of the accuracy changed after applying Kfold:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('from:')\n",
    "print(round(metrics.accuracy_score(y_test, y_pred), 5))\n",
    "print('to:')\n",
    "print(round(result.mean(), 5))\n",
    "print('This is because we only use: {0:0.2f}% of our dataset to train the model!'.format(((k_fold_split-1)/k_fold_split)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "# note: only a single metric is permitted for parameter 'scoring'\n",
    "# for all parameters for scoring, see source:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "result_f1_weighted = cross_val_score(clf, X_train_res, y_train_res, cv=kfold, scoring='f1_weighted')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result_f1_weighted, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result_f1_weighted.mean(), 4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"123456\"> <h2> 1.3 Cross Validation (Undersampling)  </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "result = cross_val_score(clf2, X_train_miss, y_train_miss, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result.mean(), 4), '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Conclusion: the average of the accuracy changed after applying Kfold:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('from:')\n",
    "print(round(metrics.accuracy_score(y_test, y_pred), 5))\n",
    "print('to:')\n",
    "print(round(result.mean(), 5))\n",
    "print('This is because we only use: {0:0.2f}% of our dataset to train the model!'.format(((k_fold_split-1)/k_fold_split)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "# note: only a single metric is permitted for parameter 'scoring'\n",
    "# for all parameters for scoring, see source:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "result_f1_weighted = cross_val_score(clf2, X_train_miss, y_train_miss, cv=kfold, scoring='f1_weighted')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result_f1_weighted, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result_f1_weighted.mean(), 4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"800150\"> <h2> 1.5 Model Tuning (Hyperparameters) </h2> </a>\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Define Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= ['gini', 'entropy'] \n",
    "splitter= ['best', 'random'] \n",
    "max_depth= [3,5,10] \n",
    "param_grid = dict(criterion=criterion, splitter=splitter, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Hyper-parameter tweaking on oversampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the start time\n",
    "start = time.time()\n",
    "\n",
    "# define the model\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create a grid search object\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search (Fitting your model to the training data)\n",
    "grid_result = grid.fit(X_train_res, y_train_res)\n",
    "\n",
    "# define each optimal parameter as a new variable\n",
    "optimal_criterion = grid.best_estimator_.get_params()['criterion']\n",
    "optimal_splitter = grid.best_estimator_.get_params()['splitter']\n",
    "optimal_max_depth = grid.best_estimator_.get_params()['max_depth']\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# get the time it takes for the gridsearch to run\n",
    "# source: https://blog.softhints.com/python-test-performance-and-measure-time-elapsed-in-seconds/\n",
    "# set the end time\n",
    "end = time.time()\n",
    "\n",
    "# get the elapsed execution time\n",
    "execution_time = end - start\n",
    "print(\"--- Execution time: ---\")\n",
    "print ('--- %0.3fms. --- ' % ( execution_time*1000.))\n",
    "print(\"--- %s seconds ---\" % (execution_time))\n",
    "print(\"--- %s minutes ---\" % (execution_time/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Applying the optimal hyper-parameters on oversampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the optimal hyper-parameters to the Logistic Regression Model\n",
    "clf3 = DecisionTreeClassifier(criterion=optimal_criterion, splitter=optimal_splitter, max_depth=optimal_max_depth)\n",
    "\n",
    "# fit/train the model with oversampled training set\n",
    "clf3.fit(X_train_res, y_train_res)\n",
    "\n",
    "# predict the testing set\n",
    "y_pred=clf3.predict(X_test)\n",
    "\n",
    "# print out the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"1234567\"> <h2> 2.0 Basic Model Decision Tree Classifier 'Case Rate'</h2> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variable is 'Case Rate Categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"census_covid_cat_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Death Rate Categories -- need Case Rate Categories to be the target variable\n",
    "df2 = df.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.iloc[:, 4:-7] # Features is all columns in the dataframe except the last 6 columns\n",
    "Y = df2.iloc[:, -1] # Target is the last column in the dataframe: 'Case Rate Categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"12345678\"> <h2> 2.1 Oversampling (SMOTE) </h2> </a>\n",
    "We oversample the <b> training </b> dataset, because the classes within our target variable 'Revenue' are imbalanced:\n",
    "* class 0: 84.53%\n",
    "* class 1: 15.47%\n",
    "\n",
    "Fore more information, click on detailed information from Prof. Jie Tao [link](https://github.com/DrJieTao/ba545-docs/blob/master/competition2/handling_imbalanced_data_part2.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set \n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=2019) \n",
    "\n",
    "sm = SMOTE(random_state = 2019) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train) \n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMOTE Algorithm has oversampled the instances in the minority class and made it equal to majority class:\n",
    "* Both classes (0 & 1) now have 7291 instances, the <b> training </b> dataset is balanced.\n",
    "* Class 1 increased from 1340 instances to 7291 instances, an increase of 5951 instances of class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Using KFold </b>\n",
    "For more information on the topic, please click the following [link](https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/).\n",
    "<br> The details of the package are noted [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"123456789\"> <h2> 2.2 Cross Validation (Oversampling)  </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(gnb, X, Y, cv=kfold, scoring='accuracy')\n",
    "result = cross_val_score(clf, X_train_res, y_train_res, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result.mean(), 4), '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Conclusion: the average of the accuracy changed after applying Kfold:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('from:')\n",
    "print(round(metrics.accuracy_score(y_test, y_pred), 5))\n",
    "print('to:')\n",
    "print(round(result.mean(), 5))\n",
    "print('This is because we only use: {0:0.2f}% of our dataset to train the model!'.format(((k_fold_split-1)/k_fold_split)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "# note: only a single metric is permitted for parameter 'scoring'\n",
    "# for all parameters for scoring, see source:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "result_f1_weighted = cross_val_score(clf, X_train_res, y_train_res, cv=kfold, scoring='f1_weighted')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result_f1_weighted, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result_f1_weighted.mean(), 4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"1234567891\"> <h2> 2.3 Cross Validation (Undersampling)  </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "result = cross_val_score(clf2, X_train_miss, y_train_miss, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the accuracy results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result.mean(), 4), '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Conclusion: the average of the accuracy changed after applying Kfold:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('from:')\n",
    "print(round(metrics.accuracy_score(y_test, y_pred), 5))\n",
    "print('to:')\n",
    "print(round(result.mean(), 5))\n",
    "print('This is because we only use: {0:0.2f}% of our dataset to train the model!'.format(((k_fold_split-1)/k_fold_split)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "k_fold_split = 10\n",
    "kfold = KFold(n_splits=k_fold_split, random_state=2019, shuffle=True)\n",
    "#result = cross_val_score(clf, X, Y, cv=kfold, scoring='accuracy')\n",
    "# note: only a single metric is permitted for parameter 'scoring'\n",
    "# for all parameters for scoring, see source:https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "result_f1_weighted = cross_val_score(clf2, X_train_miss, y_train_miss, cv=kfold, scoring='f1_weighted')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('All the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(result_f1_weighted, '\\n')\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average of all the weighted f1 results:')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(round(result_f1_weighted.mean(), 4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"12345678912\"> <h2> 2.4 Model Tuning (Hyperparameters) </h2> </a>\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Define Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= ['gini', 'entropy'] \n",
    "splitter= ['best', 'random'] \n",
    "max_depth= [3,5,10] \n",
    "param_grid = dict(criterion=criterion, splitter=splitter, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Hyper-parameter tweaking on oversampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the start time\n",
    "start = time.time()\n",
    "\n",
    "# define the model\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create a grid search object\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search (Fitting your model to the training data)\n",
    "grid_result = grid.fit(X_train_res, y_train_res)\n",
    "\n",
    "# define each optimal parameter as a new variable\n",
    "optimal_criterion = grid.best_estimator_.get_params()['criterion']\n",
    "optimal_splitter = grid.best_estimator_.get_params()['splitter']\n",
    "optimal_max_depth = grid.best_estimator_.get_params()['max_depth']\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# get the time it takes for the gridsearch to run\n",
    "# source: https://blog.softhints.com/python-test-performance-and-measure-time-elapsed-in-seconds/\n",
    "# set the end time\n",
    "end = time.time()\n",
    "\n",
    "# get the elapsed execution time\n",
    "execution_time = end - start\n",
    "print(\"--- Execution time: ---\")\n",
    "print ('--- %0.3fms. --- ' % ( execution_time*1000.))\n",
    "print(\"--- %s seconds ---\" % (execution_time))\n",
    "print(\"--- %s minutes ---\" % (execution_time/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Applying the optimal hyper-parameters on oversampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the optimal hyper-parameters to the Logistic Regression Model\n",
    "clf3 = DecisionTreeClassifier(criterion=optimal_criterion, splitter=optimal_splitter, max_depth=optimal_max_depth)\n",
    "\n",
    "# fit/train the model with oversampled training set\n",
    "clf3.fit(X_train_res, y_train_res)\n",
    "\n",
    "# predict the testing set\n",
    "y_pred=clf3.predict(X_test)\n",
    "\n",
    "# print out the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
